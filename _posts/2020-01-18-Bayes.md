---
layout:     post
title:      Bayes
subtitle:     贝叶斯
date:       2020-01-18
author:     Young
header-img: img/1*yBo4pYGr873BWW_90giprg.png
catalog: true
tags:
    - machine learning
    - python
---





### 基础概念

- 先验概率、条件概率
  <br>
  条件概率: 就是事件A在事件B发生的条件下发生的概率。
  - **条件概率，就是在条件为瓜的颜色是青绿的情况下，瓜是好瓜的概率**
  <br>
  
  先验概率: 在贝叶斯统计中，某一不确定量 p 的先验概率分布是在考虑"观测数据"前，能表达 p 不确定性的概率分布。它旨在描述这个不确定量的不确定程度，而不是这个不确定量的随机性。这个不确定量可以是一个参数，或者是一个隐含变量。
  - **先验概率，就是常识、经验、统计学所透露出的“因”的概率，即瓜的颜色是青绿的概率。**
  <br>
  
  后验概率: 在贝叶斯统计中，一个随机事件或者一个不确定事件的后验概率是在考虑和给出相关证据或数据后所得到的条件概率。同样，后验概率分布是一个未知量（视为随机变量）基于试验和调查后得到的概率分布。“后验”在本文中代表考虑了被测试事件的相关证据。
  
- **后验概率，就是在知道“果”之后，去推测“因”的概率，也就是说，如果已经知道瓜是好瓜，那么瓜的颜色是青绿的概率是多少**。后验和先验的关系就需要运用贝叶斯决策理论来求解。
  
- 条件概率分布
  <p align="center">
  $$
  P\left(X=x | Y=c_{k}\right)=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right), \quad k=1,2, \cdots, K
  $$
  </p>
  条件概率分布 $P(X=x \mid Y=c_k)$ 有指数级的数量的参数，假设 $x^{(j)}$ 可取值有 $S_j$ 个，$j=1,2,...,n$，Y可取值有K个，那么参数个数为 $K\prod_{j=1}^{n}S_j$。因为 X 作为特征向量维度往往很大，任意特征组合在一起的概率都考虑的话几乎没法统计出来。
  
- 条件独立性假设
  <br>
  **假设条件相互独立，求解的参数大大减少，只需要单独求解每一个 $p(x^i \mid y)$ 然后相乘**。
  
  <p align="center">
  $$
  \begin{aligned} P\left(X=x | Y=c_{k}\right) &=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right) \\ &=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right) \end{aligned}
  $$
  </p>

- 朴素贝叶斯法分类时，对给定的输入 x，通过学习到的模型计算后验概率分布$P(Y=c_k \mid X=x)$，将后验概率最大的类作为 x 的类输出。后验概率计算根据贝叶斯定理进行：

  $$
  P\left(Y=c_{k} | X=x\right)=\frac{P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}{\sum_{k} P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}
  $$
  
  你好

